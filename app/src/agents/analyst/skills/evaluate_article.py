import os
import json
import re
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import SystemMessage, HumanMessage

def get_eval_llm():
    provider = os.environ.get("LLM_PROVIDER", "ollama").lower()
    if provider == "ollama":
        base_url = os.environ.get("OLLAMA_API_URL", "http://ollama:11434").replace("/api", "") + "/v1"
        return ChatOpenAI(
            base_url=base_url,
            api_key=os.environ.get("OLLAMA_API_KEY", "ollama"),
            model=os.environ.get("OLLAMA_MODEL", "gemma3:12b-cloud")
        )
    else:
        return ChatGoogleGenerativeAI(
            model="gemini-2.0-flash",
            google_api_key=os.environ.get("GEMINI_API_KEY")
        )

@tool
def evaluate_article_tool(topic: str, title: str, content: str) -> str:
    """
    Skill: Eval√∫a el nivel t√©cnico de un art√≠culo.
    Devuelve un JSON con el 'score' (0 a 10) y un 'summary_short'.
    """
    print(f"ü§ñ [Analyst Skill: LLM] Evaluando nivel t√©cnico de: '{title[:40]}...'")
    llm = get_eval_llm()
    
    prompt = f"""
    Eres un analista t√©cnico experto en {topic}. Eval√∫a la relevancia, impacto y novedad de este art√≠culo.
    Asigna una puntuaci√≥n del 0.0 al 10.0. Un art√≠culo irrelevante o gen√©rico merece una nota mas baja que un anuncio cr√≠tico o vulnerabilidad grave.

    REGLA CR√çTICA PARA EL RESUMEN: Ve directo al grano. NO uses frases introductorias como "Este art√≠culo trata de...". Escribe directamente el hecho principal (ej: "Se ha descubierto una vulnerabilidad cr√≠tica en...").
    
    T√≠tulo: {title}
    Contenido: {content[:1500]}
    
    IMPORTANTE: Devuelve √öNICAMENTE un objeto JSON v√°lido. El 'score' DEBE ser tu propia evaluaci√≥n matem√°tica, NO COPIES EL EJEMPLO:
    {{
        "score": 7.3,
        "summary_short": "Resumen muy breve y directo de 2 l√≠neas."
    }}
    """
    
    messages = [
        SystemMessage(content="You are a strict JSON-only evaluation engine."),
        HumanMessage(content=prompt)
    ]
    
    try:
        response = llm.invoke(messages)
        content_res = response.content.strip()
        
        # --- EL LIMPIADOR DE JSON ---
        content_res = content_res.replace("```json", "").replace("```", "").strip()
        match = re.search(r'\{.*\}', content_res, re.DOTALL)
        
        if match:
            clean_json_str = match.group(0)
            json.loads(clean_json_str) # Comprobamos que no explota
            return clean_json_str
        else:
            raise ValueError("No se encontr√≥ estructura JSON")
            
    except Exception as e:
        print(f"‚ùå [Analyst Skill] Error de formato: {e}")
        # Si todo falla, devolvemos un JSON v√°lido para que Python no pete
        return json.dumps({
            "score": 5.0,
            "summary_short": f"No se pudo evaluar autom√°ticamente el art√≠culo."
        })