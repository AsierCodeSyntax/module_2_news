{
  "generated_at": "2026-02-27T08:44:49.831387+00:00",
  "topics": {
    "plone": {
      "window_days": 14,
      "since": "2026-02-13T08:44:49.831330+00:00",
      "until": "2026-02-27T08:44:49.831330+00:00",
      "items": []
    },
    "django": {
      "window_days": 7,
      "since": "2026-02-20T08:44:49.831330+00:00",
      "until": "2026-02-27T08:44:49.831330+00:00",
      "items": []
    },
    "ai": {
      "window_days": 7,
      "since": "2026-02-20T08:44:49.831330+00:00",
      "until": "2026-02-27T08:44:49.831330+00:00",
      "sections": [
        {
          "name": "industry",
          "items": []
        },
        {
          "name": "arxiv",
          "items": [
            {
              "id": 16122,
              "topic": "ai",
              "source_id": "arxiv_cs_ai",
              "title": "Ikasketa-abiaduraren transferentziaren froga μP-rekin",
              "url": "https://arxiv.org/abs/2511.01734",
              "published_at": "2026-02-26T05:00:00+00:00",
              "priority": 40,
              "tags": [
                "arxiv",
                "learning",
                "rate",
                "under",
                "proof",
                "transfer",
                "provide",
                "width",
                "neural"
              ],
              "summary_short": "Lan berri batek ikasketa-abiaduraren transferentziaren lehen froga ematen du zabalerarekin, μP-rekin parametrizatutako geruza anitzeko pertzeptroi lineal (MLP) batean. Horren arabera, ikasketa-abiadura optimoa zero ez den konstante batera konbergitzen da zabalera infinitura doan heinean, ikasketa-abiaduraren transferentziari azalpen teorikoa emanez. Propietate hau ez da betetzen beste parametrizazio alternatibo batzuekin, hala nola Standard Parametrization (SP) eta Neural Tangent Parametrization (NTP).",
              "llm_score": 9.0
            },
            {
              "id": 15158,
              "topic": "ai",
              "source_id": "arxiv_cs_lg",
              "title": "Banaketa Anitzeko Ikaskuntza PAC Ikaskuntza bezain Erraza al da: Tasa Zehatzak Etiketa Zarataren Mugarekin",
              "url": "https://arxiv.org/abs/2602.21039",
              "published_at": "2026-02-25T05:00:00+00:00",
              "priority": 40,
              "tags": [
                "arxiv",
                "learning",
                "noise",
                "multi-distribution",
                "rates",
                "bounded",
                "statistical",
                "each",
                "label"
              ],
              "summary_short": "ArXiv-en argitaratutako lan berri batek banaketa anitzeko ikaskuntza aztertzen du, etiketa zarataren muga egoeran zentratuz. Banaketa bakoitza bereizita ikasten ez bada, frogatzen du banaketa anitzetan ikasteak berez k/epsilon^2-rekin eskalatzen duten tasa motelak eragiten dituela, zarata maila konstanteetan ere. Lan honek sailkapen zarata aleatorioaren eta Massart zarataren arteko bereizketa estatistikoa ezartzen du, iturri anitzetatik ikasteko oztopo bereizgarri bat azpimarratuz.",
              "llm_score": 9.0
            },
            {
              "id": 15207,
              "topic": "ai",
              "source_id": "arxiv_cs_lg",
              "title": "Auto-Bilketa Errekurtsiboak Pentsamendu Sakona Ahalbidetzen du Hizkuntza Eredu Handietan",
              "url": "https://arxiv.org/abs/2509.26626",
              "published_at": "2026-02-25T05:00:00+00:00",
              "priority": 40,
              "tags": [
                "arxiv",
                "rsa",
                "performance",
                "models",
                "scaling",
                "compute",
                "parallel",
                "reasoning",
                "recursive"
              ],
              "summary_short": "Ikerlariek Auto-Bilketa Errekurtsiboa (RSA) proposatzen dute, LLMentzako test-denborako eskalatze metodo bat, eskalatze paraleloa eta sekuentziala konbinatzen dituena. RSAk arrazoibide kate posibleak fintzen ditu azpimultzoen bilketaren bidez, soluzioak iteratiboki hobetuz. Gemini 3 Flash-ekin RSAk ARC-AGI-2 sailkapeneko goiko postuetatik gertu lortzen du errendimendua, eta Qwen3-4B-Instruct-2507 arrazoitze eredu handiagoen parekoa da. Bilketaz jabetzen den indartze bidezko ikaskuntza metodo berri batek errendimendua are gehiago hobetzen du.",
              "llm_score": 9.0
            },
            {
              "id": 15138,
              "topic": "ai",
              "source_id": "arxiv_cs_lg",
              "title": "Transformadore estandarrek Minimax tasa lortzen dute $C^{s,\\lambda}$ helburuekin erregresio ez-parametrikoan",
              "url": "https://arxiv.org/abs/2602.20555",
              "published_at": "2026-02-25T05:00:00+00:00",
              "priority": 40,
              "tags": [
                "arxiv",
                "transformers",
                "standard",
                "lambda",
                "transformer",
                "achieve",
                "minimax",
                "rate",
                "nonparametric"
              ],
              "summary_short": "Ikerketa-lan berri batek frogatzen du Transformer estandarrek H\"older funtzioak edozein zehaztasunekin hurbil ditzaketela eta minimax tasa optimoak lortzen dituztela H\"older helburu-funtzioetarako erregresio ez-parametrikoan. Lan honek Transformer-en egiturak karakterizatzeko metrikak aurkezten ditu eta Transformer-en Lipschitz konstanteari eta memorizazio ahalmenari buruzko goiko mugak ematen ditu.",
              "llm_score": 9.0
            },
            {
              "id": 15181,
              "topic": "ai",
              "source_id": "arxiv_cs_lg",
              "title": "Armijo lerro-bilaketak gradientearen deskribapen (estokastikoa) azkarrago egin dezake, frogagarriki",
              "url": "https://arxiv.org/abs/2503.00229",
              "published_at": "2026-02-25T05:00:00+00:00",
              "priority": 40,
              "tags": [
                "arxiv",
                "gradient",
                "gd-ls",
                "convergence",
                "line-search",
                "stochastic",
                "armijo-ls",
                "smoothness",
                "armijo"
              ],
              "summary_short": "Lan berri batek erakusten du Armijo lerro-bilaketak (Armijo-LS) gradientearen deskribapenean (GD) erabilita konbergentzia-tasa azkarragoak ekar ditzakeela GD-rekin alderatuta, urrats-tamaina finko batekin (1/L) helburu-funtzio konbexu eta ez-konbexu batzuetarako, eta potentzialki ezarpen horietarako berariaz diseinatutako algoritmoen errendimendua berdindu dezakeela. Artikuluak GD estokastikoa ere aztertzen du lerro-bilaketa estokastiko batekin galera konbexuen gainean interpolazio-suposizioaren arabera.",
              "llm_score": 9.0
            }
          ]
        }
      ]
    }
  }
}